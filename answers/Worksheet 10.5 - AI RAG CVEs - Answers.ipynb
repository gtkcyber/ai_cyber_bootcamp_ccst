{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"../img/GTK_Logo_Social Icon.jpg\" width=175 align=\"right\" />\n",
    "\n",
    "# AI: Retrieval Augmented Generation (RAG)\n",
    "\n",
    "This notebook shows how to build a semantic search engine using **RAG**. \n",
    "\n",
    "The task is to build a model that will be able to take in a plain language query and find the most relevant documents to answer this query. \n",
    "\n",
    "#### Data: \n",
    "[https://www.kaggle.com/datasets/manavkhambhayata/cve-2024-database-exploits-cvss-os](https://www.kaggle.com/datasets/manavkhambhayata/cve-2024-database-exploits-cvss-os)\n",
    "\n",
    "The data comes from the National Vulnerability Database (NVD), a government-managed repository of cybersecurity vulnerabilities. It provides detailed information on security issues, including severity scores and affected systems.\n",
    "\n",
    "The dataset was extracted using the NVD API and processed with Python. It includes vulnerabilities published between January 1, 2024, and January 15, 2024, with key details such as CVE ID, description, CVSS score, attack vector, and affected operating systems.\n",
    "\n",
    "#### Libraries:\n",
    "\n",
    "Many of the applications you build with LangChain will contain multiple steps with multiple invocations of LLM calls. As these applications get more and more complex, it becomes crucial to be able to inspect what exactly is going on inside your chain or agent. The best way to do this is with LangSmith. You will need to sign up for an account and generate an API key that you will enter below. [LangSmith](https://smith.langchain.com/?_gl=1*1c7os5z*_ga*MTk2ODA2OTQ4Ny4xNzUzODY4NjM2*_ga_47WX3HKKY2*czE3NTM4Njc4ODEkbzEkZzEkdDE3NTM4Njc4OTYkajQ1JGwwJGgw)\n",
    "\n",
    "- [langchain](https://www.langchain.com/langchain)\n",
    "- [getpass](https://docs.python.org/3/library/getpass.html) Prompt the user for a password without echoing.\n",
    "- `<a model server for embedding models> ` depending on which platform you use to pull your model embeddings, you will need their langchain library. e.g. openai, azure, this example uses huggingface\n",
    "- [langchain-huggingface](https://anaconda.org/conda-forge/langchain-huggingface)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:01:58.073544Z",
     "start_time": "2025-07-31T02:01:58.069278Z"
    }
   },
   "source": [
    "# Load Libraries - Make sure to run this cell!\n",
    "import getpass\n",
    "import os\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Langchain has a variety of nice modules that help you load different formats of documents. [document loaders](https://python.langchain.com/docs/how_to/#document-loaders)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:01:59.568927Z",
     "start_time": "2025-07-31T02:01:59.566138Z"
    }
   },
   "source": [
    "DATA_HOME = '../data/'\n",
    "\n",
    "filename_cves = 'nvd_vulnerabilities_with_os.csv'"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:02:03.327471Z",
     "start_time": "2025-07-31T02:02:03.055597Z"
    }
   },
   "source": [
    "loader = CSVLoader(\n",
    "    file_path=DATA_HOME + filename_cves, \n",
    "    source_column='CVE ID',\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",\n",
    "        \"quotechar\": '\"',\n",
    "    },\n",
    "     encoding=\"UTF-8\"\n",
    ")\n",
    "\n",
    "docs_raw = loader.load()\n",
    "for record in docs_raw[:2]:\n",
    "    print(record)\n",
    "    print('----------')"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error loading ../data/nvd_vulnerabilities_with_os.csv",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_community/document_loaders/csv_loader.py:134\u001B[0m, in \u001B[0;36mCSVLoader.lazy_load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 134\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m csvfile:\n\u001B[1;32m    135\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__read_file(csvfile)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../data/nvd_vulnerabilities_with_os.csv'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 11\u001B[0m\n\u001B[1;32m      1\u001B[0m loader \u001B[38;5;241m=\u001B[39m CSVLoader(\n\u001B[1;32m      2\u001B[0m     file_path\u001B[38;5;241m=\u001B[39mDATA_HOME \u001B[38;5;241m+\u001B[39m filename_cves, \n\u001B[1;32m      3\u001B[0m     source_column\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCVE ID\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m      8\u001B[0m      encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUTF-8\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      9\u001B[0m )\n\u001B[0;32m---> 11\u001B[0m docs_raw \u001B[38;5;241m=\u001B[39m \u001B[43mloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m record \u001B[38;5;129;01min\u001B[39;00m docs_raw[:\u001B[38;5;241m2\u001B[39m]:\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mprint\u001B[39m(record)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_core/document_loaders/base.py:32\u001B[0m, in \u001B[0;36mBaseLoader.load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[Document]:\n\u001B[1;32m     31\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load data into Document objects.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlazy_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/langchain_community/document_loaders/csv_loader.py:151\u001B[0m, in \u001B[0;36mCSVLoader.lazy_load\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    149\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError loading \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 151\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError loading \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Error loading ../data/nvd_vulnerabilities_with_os.csv"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Embeddings\n",
    "\n",
    "You can generate the templated code you need based on the model server you want to use. Go to the langchain site and select your preferred server from the dropdown menu.  They have many options, openai, azure, google, aws, anthropic, etc. Below I am using huggingface. [https://python.langchain.com/docs/tutorials/retrievers/#embeddings](https://python.langchain.com/docs/tutorials/retrievers/#embeddings)\n",
    "\n",
    "You have some decisions to make at this point: \n",
    "\n",
    "**Decision 1**: Select model server (or this is where you could access a downloaded model if working in an airgapped environment)\n",
    "\n",
    "**Decision 2**: Select the specific model to use to generate your embeddings. Since we are doing a semantic search engine, you will want something that is good at that task like a sentence-transformer. This is where you can end up with something that is great for your task, or something that is terrible. Once you have your pipeline, you will want to try out some different models to see how the results change. Things to consider:\n",
    "\n",
    " - size (larger might be better)\n",
    " - tokenizer (do you need multi-language capabilities?, this is where you would ensure it has seen your languages)\n",
    " - origin (use something that comes from a reputable source, be weary of things that have been fine-tuned by random people in places like huggingface. go for the ones from Microsoft, Facebook etc)\n",
    " - content for training (do you need to know this? if so, you'll want an open source model)\n",
    " - input length (models can only take in a specific number of tokens, older, smaller models have a smaller amount of tokens they can take in which affects your ability to embed large/long texts\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:03:39.354757Z",
     "start_time": "2025-07-31T02:03:32.461958Z"
    }
   },
   "source": [
    "# you will need to grab your API token for the server you choose\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass()"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6d21a3092449cca28ce790ea45dde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bceeb66e75c41d593f5faba9c81f2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3b230963dc44cd98446e77662ae179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6ac4d03394b4c5a92a120ad2cdd05d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfafde072784450fb12cba9c9ba5459f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554e431b005a41b882f2258fb11bfe78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acc3cda1bf7407ebd096cc30c7b0db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2ebb184a6d430a953626b45ced8512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f272e4961043d2b78641371490d86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b987e534c248b8973932f222ca0dc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a23def24b26b403faae1c005f94d7ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\")# all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try out your new embedding model on a few of our documents. The **embed_query** method is typically used to embed a single sentence, like we do for an incoming query, which is why it's useful here to just see what it does on one document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated vectors of length 768\n",
      "\n",
      "[-0.033642400056123734, -0.029917238280177116, 0.004915493540465832, -0.00423580314964056, 0.00263518700376153, -0.0005402038223110139, 0.01388082280755043, 0.027193713933229446, 0.007828943431377411, -0.024739526212215424]\n"
     ]
    }
   ],
   "source": [
    "vector_1 = embeddings.embed_query(docs_raw[0].page_content)\n",
    "vector_2 = embeddings.embed_query(docs_raw[1].page_content)\n",
    "\n",
    "assert len(vector_1) == len(vector_2)\n",
    "print(f\"Generated vectors of length {len(vector_1)}\\n\")\n",
    "print(vector_1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage\n",
    "Now that we know how to embed our documents, we will need to store these embeddings in a database. There are many options for doing this, but the most effecient way to store embeddings is in a **vector database**. These have been optimized to store and retrieve these kinds of embeddings, so when you can use them, you should. You can also use more traditional things like MongoBD or Elasticsearch with specific field types for storing a dense vector. This is useful if you need to store a lot of metadata or continue to have the option do to a keyword search in addition to the semantic search (this is common). "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-31T02:03:53.498143Z",
     "start_time": "2025-07-31T02:03:53.444710Z"
    }
   },
   "source": "vector_store = InMemoryVectorStore(embeddings)",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_core\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvectorstores\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m InMemoryVectorStore\n\u001B[0;32m----> 3\u001B[0m vector_store \u001B[38;5;241m=\u001B[39m InMemoryVectorStore(\u001B[43membeddings\u001B[49m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_memory = vector_store.add_documents(documents=docs_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search\n",
    "we will use similarity search (which uses cosine simliarity) to find the documents that are the most similar to our query. Then look at the 5 most relevant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='CVE ID: CVE-2024-0223\n",
      "Description: Heap buffer overflow in ANGLE in Google Chrome prior to 120.0.6099.199 allowed a remote attacker to potentially exploit heap corruption via a crafted HTML page. (Chromium security severity: High)\n",
      "CVSS Score: 8.8\n",
      "Attack Vector: CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H\n",
      "Affected OS: Fedoraproject Fedora 39, Fedoraproject Fedora 38' metadata={'source': 'CVE-2024-0223', 'row': 223}\n",
      "-----\n",
      "page_content='CVE ID: CVE-2024-0225\n",
      "Description: Use after free in WebGPU in Google Chrome prior to 120.0.6099.199 allowed a remote attacker to potentially exploit heap corruption via a crafted HTML page. (Chromium security severity: High)\n",
      "CVSS Score: 8.8\n",
      "Attack Vector: CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H\n",
      "Affected OS: Fedoraproject Fedora 39, Fedoraproject Fedora 38' metadata={'source': 'CVE-2024-0225', 'row': 225}\n",
      "-----\n",
      "page_content='CVE ID: CVE-2024-0222\n",
      "Description: Use after free in ANGLE in Google Chrome prior to 120.0.6099.199 allowed a remote attacker who had compromised the renderer process to potentially exploit heap corruption via a crafted HTML page. (Chromium security severity: High)\n",
      "CVSS Score: 8.8\n",
      "Attack Vector: CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H\n",
      "Affected OS: Fedoraproject Fedora 39, Fedoraproject Fedora 38' metadata={'source': 'CVE-2024-0222', 'row': 222}\n",
      "-----\n",
      "page_content='CVE ID: CVE-2024-0224\n",
      "Description: Use after free in WebAudio in Google Chrome prior to 120.0.6099.199 allowed a remote attacker to potentially exploit heap corruption via a crafted HTML page. (Chromium security severity: High)\n",
      "CVSS Score: 8.8\n",
      "Attack Vector: CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H\n",
      "Affected OS: Fedoraproject Fedora 39, Fedoraproject Fedora 38' metadata={'source': 'CVE-2024-0224', 'row': 224}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"Chrome vulnerabilities to heap corruption in May.\"\n",
    ")\n",
    "for doc in results[0:5]:\n",
    "    print(doc)\n",
    "    print('-----')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search 2\n",
    "Return documents based on similarity to an embedded query.Now we want to embed out query (USING THE SAME EMBEDDING MODEL AS THE DOCS). Then compare our query's vector to the database vectors and get the ones with the smallest distance between the 2. There are multiple ways to calculate the *distance* between 2 vectors, but the most popular for this task is cosine similarity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='CVE ID: CVE-2023-42136\n",
      "Description: PAX Android based POS devices with PayDroid_8.1.0_Sagittarius_V11.1.50_20230614 or earlier can allow the execution of arbitrary commands with system account privilege by shell injection starting with a specific word.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The attacker must have shell access to the device in order to exploit this vulnerability.\n",
      "CVSS Score: 7.8\n",
      "Attack Vector: CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H\n",
      "Affected OS: Paxtechnology Paydroid' metadata={'source': 'CVE-2023-42136', 'row': 1284}\n",
      "-----\n",
      "page_content='CVE ID: CVE-2023-47560\n",
      "Description: An OS command injection vulnerability has been reported to affect QuMagie. If exploited, the vulnerability could allow authenticated users to execute commands via a network.\n",
      "\n",
      "We have already fixed the vulnerability in the following version:\n",
      "QuMagie 2.2.1 and later\n",
      "CVSS Score: 7.4\n",
      "Attack Vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:C/C:L/I:L/A:L\n",
      "Affected OS: N/A' metadata={'source': 'CVE-2023-47560', 'row': 341}\n",
      "-----\n",
      "page_content='CVE ID: CVE-2023-39294\n",
      "Description: An OS command injection vulnerability has been reported to affect several QNAP operating system versions. If exploited, the vulnerability could allow authenticated administrators to execute commands via a network.\n",
      "\n",
      "We have already fixed the vulnerability in the following versions:\n",
      "QTS 5.1.3.2578 build 20231110 and later\n",
      "QuTS hero h5.1.3.2578 build 20231110 and later\n",
      "CVSS Score: 6.6\n",
      "Attack Vector: CVSS:3.1/AV:N/AC:L/PR:H/UI:N/S:C/C:L/I:L/A:L\n",
      "Affected OS: Qnap Quts Hero h5.1.0.2424, Qnap Qts 5.1.1.2491, Qnap Qts 5.1.0.2444, Qnap Quts Hero h5.1.1.2488, Qnap Qts 5.1.0.2348, Qnap Quts Hero h5.1.0.2453, Qnap Qts 5.1.2.2533, Qnap Quts Hero h5.1.2.2534, Qnap Qts 5.1.0.2418, Qnap Qts 5.1.0.2399, Qnap Quts Hero h5.1.0.2466, Qnap Qts 5.1.0.2466, Qnap Quts Hero h5.1.0.2409' metadata={'source': 'CVE-2023-39294', 'row': 325}\n",
      "-----\n",
      "page_content='CVE ID: CVE-2023-41289\n",
      "Description: An OS command injection vulnerability has been reported to affect QcalAgent. If exploited, the vulnerability could allow authenticated users to execute commands via a network.\n",
      "\n",
      "We have already fixed the vulnerability in the following version:\n",
      "QcalAgent 1.1.8 and later\n",
      "CVSS Score: 6.3\n",
      "Attack Vector: CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:L\n",
      "Affected OS: N/A' metadata={'source': 'CVE-2023-41289', 'row': 329}\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "embedding = embeddings.embed_query(\"Which phone os is the most vulnerable to shell injection?\")\n",
    "\n",
    "results = vector_store.similarity_search_by_vector(embedding)\n",
    "for doc in results[0:5]:\n",
    "    print(doc)\n",
    "    print('-----')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generated Answers\n",
    "this RAG architecture is usually part 1 of a chatbot (and many other products). This gets us the relevant source documents for a user's query, then we take these top X docs and give them to a generative model to generate an answer to our question BASED on these documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
