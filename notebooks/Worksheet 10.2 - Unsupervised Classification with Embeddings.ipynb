{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Unsupervised Classification with Embeddings - Answers\n",
    "In this lab, we will be working on the following use case:  You run your company's IT and want to make sure that your employees are not signing up for unauthorized services and creating shadow IT.  To do so, we will be building a model to idenfity account verification emails sent to company email addresses.\n",
    "\n",
    "## Finding SaaS Applications\n",
    "The basic approach is that we're going to look at the subjects of emails and compare that subject with the subject(s) of common account operations.  This initial approach starts with email verification emails, but could be expanded to other common SaaS operations such as 2FA, account creation, etc.\n",
    "\n",
    "First, let's read in the data.  As with other labs, this lab uses the `DATA_PATH` variable so if you moved the data anywhere outside of the repository, you will need to modify the `DATA_PATH` variable.  The dataset we will be using for this exercise is in the file `clean_email.csv` which contains approximately 140k email metadata events."
   ],
   "id": "c5d92648ec2423b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# These two lines should only be used on a Mac with Apple Silicon.  If you have a GPU, you can use that as well.\n",
    "import torch\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "DATA_PATH = '../data'\n",
    "\n",
    "# You'll need to define a verification message which we will use to compare all the other subjects to.\n",
    "VERIFICATION_TEXT = \"please verify your email\"\n"
   ],
   "id": "30767b678990aa04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The Data\n",
    "Let's read in the data and do some EDA."
   ],
   "id": "d01417a460c58855"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "email_data = pd.read_csv(f\"{DATA_PATH}/clean_email.csv\")",
   "id": "995ead4d2640785d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "email_data.sample(5)",
   "id": "f72e5653b85a2127",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "You should do some exploratory data analysis here to make sure that all the fields you need are populated.",
   "id": "1ee12766b1fa5706"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def cleanup_subject(subject: str) -> str:\n",
    "    # Remove newlines\n",
    "    subject = subject.replace('\\n', ' ')\n",
    "\n",
    "    # Remove leading and trailing whitespace\n",
    "    subject = subject.strip()\n",
    "\n",
    "    # Convert to lowercase\n",
    "    subject = subject.lower()\n",
    "    return subject\n"
   ],
   "id": "22c3fcb808b0ab7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Drop rows with an empty subject\n",
    "\n",
    "\n",
    "# Clean up the subject using function above"
   ],
   "id": "7eedb17158ec6993",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step One:  Generate Embeddings\n",
    "After exploring and cleaning our data, we'll need to compute embeddings for the subject lines of the emails.  You can use a similar method as we did in previous labs OR you can use a library which I really like called `fasttext`.  In the answer notebook, you will see both methods, but the basic idea is the same.  You can use the same embedding model we used in the previous lab to generate the embeddings.\n",
    "\n",
    "**This step will take several minutes to complete.**"
   ],
   "id": "aafac421a701cc0c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Load embedding model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2', device=device)\n",
    "# Generate embeddings. Use the model encode function to accomplish this\n"
   ],
   "id": "d2fd793e412e77f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# You should also create embeddings for the verification text\n",
    "# You will need to reshape it so that we can compute the cosine_similarity.  Use the reshape(1, -1)\n",
    "VERIFICATION_EMBEDDING = # Your code here..."
   ],
   "id": "5f22a9af7962cbbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step Two: Comparing the Embeddings\n",
    "What we will need to do her is create a verification text, something like `Please Verify your Email Address` and then we will use cosine similiarity to compare the embeddings for the verification text and the email subjects.\n",
    "\n",
    "### Calculate the Cosine Similiarity\n",
    "\n",
    "Next, we calculate the cosine similarity between the template text and the email subject.  We have to do some data cleanup as well.  For the cleanup we:\n",
    "1. Convert the inputs to strings\n",
    "2. Remove leading/trailing whitespaces\n",
    "3. Replace any newlines with spaces\n",
    "4. Convert to lower case\n",
    "\n",
    "Once we have done that, we'll use the model to get a vector of the sentence and use cosine similiarity to compute the distance between the template text and the email subject.\n",
    "\n",
    "You will have to reshape the lists using the `reshape(1,-1)` function in numpy.  To do this, you'll probably have to convert the series to a NumPy array as shown below:\n",
    "\n",
    "```python\n",
    "np.array(embedding).reshape(1, -1)\n",
    "```\n",
    "\n",
    "You can calculate the cosine similarity by using the `cosine_similarity(a1, a2)` that we imported at the beginning of the lab.  `a1` and `a2` need to be list-like data structures.  Be sure to save these scores in the dataframe."
   ],
   "id": "9f1f2dee6eb87806"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def text_similarity(embedding) -> float:\n",
    "    return cosine_similarity( #Your code here.... )[0][0]\n",
    "\n",
    "email_data['similarity_score'] = # Your code here..."
   ],
   "id": "6b4cd13cd1fd2dcc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step Three:  Finding the Accounts.\n",
    "Now that we have the similarity scores, we can look at the results to find candidate emails.  The closer the similarity score is to 1, the more likely the email is a match. You will have to decide what similarity threshold you want to use to detect these emails.  Experiment with the similarity score to see what threshold works best for our use case.\n",
    "\n",
    "Your task here is to find the emails, then extract the unique sender domains to find out which unauthorized accounts have been created."
   ],
   "id": "a156f92e735e3bdd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Your code here...",
   "id": "299cb3f2a1c2423d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
